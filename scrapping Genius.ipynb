{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib, os, urllib.request\n",
    "import re\n",
    "import requests\n",
    "from mutagen.mp3 import MP3\n",
    "from mutagen.id3 import ID3, TIT2\n",
    "import os\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.expanduser(r\"words.csv\"), \"wb\")\n",
    "for i in range(ord('A') ,ord('Z')+1):\n",
    "    letter = chr(i)+\"\\n\"\n",
    "    file.write(bytes(letter,encoding=\"ascii\", errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urlify(s):\n",
    "\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "\n",
    "    # Replace all runs of whitespace with a single dash\n",
    "    s = re.sub(r\"\\s+\", '-', s)\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\MUSIC\\sounds\\RAP\\Eminem'\n",
    "files = []\n",
    "urls = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    i=0\n",
    "    for file in f:\n",
    "        if '.mp3' in file :\n",
    "            files.append(os.path.join(r, file))\n",
    "for f in files:\n",
    "    try :\n",
    "        tags = ID3(os.path.join(r,f))\n",
    "        if 'TIT2' in tags:\n",
    "            #songName = urlify(tags['TIT2'].text[0])\n",
    "            songName = tags['TIT2'].text[0]\n",
    "            songName = re.sub(r\"feat+.([^\\w]|[\\w])*\",\"\",songName,flags=re.IGNORECASE)\n",
    "            songName = urlify(songName)\n",
    "            songName = songName.replace(\"'\",'')\n",
    "            if songName[-1]=='-':\n",
    "                songName = songName[:-1]\n",
    "            url = \"https://genius.com/eminem-\"+songName+\"-lyrics\"\n",
    "            #print(url)\n",
    "            if not url in urls:\n",
    "                urls.append(url)\n",
    "    except :\n",
    "        tags = ID3()\n",
    "#urls = list(set(urls))\n",
    "urlsFile = open(os.path.expanduser(r\"urls.csv\"),\"wb\")\n",
    "for url in urls:\n",
    "    urlsFile.write(bytes(url+\"\\n\",encoding=\"ascii\", errors='ignore'))\n",
    "print('kammalt')\n",
    "urlsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "notWorkingUrls = []\n",
    "workingURLS =[]\n",
    "with open(os.path.expanduser(r\"urls.csv\"),\"r\") as urlsFile:\n",
    "   # urls = csv.reader(urlsFile, delimiter=' ', quotechar='|')\n",
    "    for url in urlsFile:\n",
    "        urls.append(url)\n",
    "urlsFile.close()\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36',\n",
    "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "         'Referer': 'https://cssspritegenerator.com',\n",
    "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "         'Accept-Encoding': 'none',\n",
    "         'Accept-Language': 'en-US,en;q=0.8',\n",
    "         'Connection': 'keep-alive'}\n",
    "i=0\n",
    "for url in urls:\n",
    "    i=i+1\n",
    "    print(i)\n",
    "    try:\n",
    "        req=urllib.request.Request(url,headers=hdr)\n",
    "        thePage = urllib.request.urlopen(req)\n",
    "        soup = BeautifulSoup(thePage, \"html.parser\")\n",
    "        title = soup.find('div',class_='header_with_cover_art-primary_info').h1.text\n",
    "        title = re.sub(r'/',\"-\",title)\n",
    "        workingURLS.append(url)\n",
    "        #workingURLS.append([url,title])\n",
    "    except urllib.error.HTTPError as err:\n",
    "        if err.code == 404:\n",
    "            notWorkingUrls.append(url)\n",
    "        else:\n",
    "            raise\n",
    "notUrlsFile = open(os.path.expanduser(r\"not-working-urls.csv\"),\"wb\")\n",
    "for url in notWorkingUrls :\n",
    "    urls.remove(url)\n",
    "    notUrlsFile.write(bytes(url,encoding=\"ascii\", errors='ignore'))\n",
    "notUrlsFile.close()\n",
    "urlsFile = open(os.path.expanduser(r\"workingUrls.csv\"),\"wb\")\n",
    "for url in workingURLS:\n",
    "    urlsFile.write(bytes(url,encoding=\"ascii\", errors='ignore'))\n",
    "urlsFile.close()\n",
    "    \n",
    "print('kammalt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsFile = open(os.path.expanduser(r\"workingUrls.csv\"),\"wb\")\n",
    "urls = list(dict.fromkeys(urls))\n",
    "for url in urls:\n",
    "    urlsFile.write(bytes(url,encoding=\"ascii\", errors='ignore'))\n",
    "print('kammalt')\n",
    "urlsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lyricsPath = os.getcwd()+'\\\\songs_lyrics'\n",
    "if not os.path.exists(lyricsPath):\n",
    "    os.makedirs(lyricsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "i=0\n",
    "with open(os.path.expanduser(r\"workingUrls.csv\"),\"r\") as urlsFile:\n",
    "   # urls = csv.reader(urlsFile, delimiter=' ', quotechar='|')\n",
    "    for url in urlsFile:\n",
    "        urls.append(url)\n",
    "urlsFile.close()\n",
    "urls.sort()\n",
    "urls = list(dict.fromkeys(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existingUrls = []\n",
    "if os.path.isfile(lyricsPath+r'\\existing-urls.csv'):\n",
    "    with open(os.path.expanduser(lyricsPath+r'\\existing-urls.csv'),'r') as existingUrlsFile:\n",
    "        for url in existingUrlsFile:\n",
    "            url = re.sub(r'.*url : ', '',url)\n",
    "            existingUrls.append(url)\n",
    "    existingUrlsFile.close()\n",
    "    existingUrls.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(lyricsPath+r'\\existing-urls.csv'):\n",
    "    existingUrlsFile = open(os.path.expanduser(lyricsPath+r'\\existing-urls.csv'),'ab')\n",
    "else:\n",
    "    existingUrlsFile = open(os.path.expanduser(lyricsPath+r'\\existing-urls.csv'),'wb')\n",
    "\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36',\n",
    "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "         'Referer': 'https://cssspritegenerator.com',\n",
    "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "         'Accept-Encoding': 'none',\n",
    "         'Accept-Language': 'en-US,en;q=0.8',\n",
    "         'Connection': 'keep-alive'}\n",
    "i=0\n",
    "for url in urls :\n",
    "    print(url)\n",
    "    if  not url in existingUrls:\n",
    "        try:\n",
    "            req=urllib.request.Request(url,headers=hdr)\n",
    "            thePage = urllib.request.urlopen(req)\n",
    "            soup = BeautifulSoup(thePage, \"lxml\")\n",
    "            lyrics = soup.find('div', class_=\"lyrics\").p.text\n",
    "            title = soup.find('div',class_='header_with_cover_art-primary_info').h1.text\n",
    "            title = re.sub(r'/',\"-\",title)\n",
    "            title = re.sub(r'[^\\w\\s]|(\\-\\(\\)\\')','',title)\n",
    "            artist = soup.find('div',class_='header_with_cover_art-primary_info').h2.text.lstrip().rstrip()\n",
    "            if not os.path.exists(lyricsPath+\"\\\\\"+title+\".txt\"):\n",
    "                songFile = open(os.path.expanduser(lyricsPath+\"\\\\\"+title+\".txt\"),\"wb\")\n",
    "                songFile.write(bytes(\"Title : \"+title+\"\\nArtist : \"+artist+\"\\nLyrics :\\n\"+lyrics,encoding=\"ascii\", errors='ignore'))\n",
    "                songFile.close()\n",
    "                existingUrlsFile.write(bytes(\"Title : \"+title+\" , url : \"+url,encoding=\"ascii\", errors='ignore'))\n",
    "                i = i+1\n",
    "                print(urls[urls.index(url)])\n",
    "        except urllib.error.HTTPError as err:\n",
    "            raise\n",
    "existingUrlsFile.close()\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existingUrlsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
